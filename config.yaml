# STT Benchmark Configuration

# Models to benchmark
models:
  # Custom Models
  - name: "whisper-turbo-28000"
    type: "whisper"
    path: "/home/ubuntu/tts-demo/whisper-multi-train/Whisper-Finetune/output/whisper-large-v3-turbo/checkpoint-28000"
    enabled: true




# Datasets to use for benchmarking
datasets:
  - name: "freyavoice-uyumsoft-benchmark"
    path: "freyavoice/uyumsoft-benchmark"
    split: "train"
    enabled: true


# Benchmark settings
benchmark:
  # Batch processing (for efficiency)
  batch_size: 1  # Increase for faster processing (if GPU memory allows)
  
  # Generation parameters
  max_new_tokens: 400
  num_beams: 5
  
  # Device configuration
  device: "auto"  # auto, cuda, cpu, or mps
  torch_dtype: "float16"  # float16 (faster) or float32 (more accurate)
  
  # Performance tuning
  use_bettertransformer: true  # Enable BetterTransformer if available
  compile_model: false  # Use torch.compile (PyTorch 2.0+, experimental)


# API server settings
api:
  host: "0.0.0.0"
  port: 8000
  reload: false  # Enable for development



output:
  results_dir: "results"
  cache_dir: "cache"
  save_transcriptions: true
  save_metrics: true
  save_visualizations: true
  save_detailed_results: true